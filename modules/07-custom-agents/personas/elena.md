# Elena's Journey: Module 7 - Custom Agents

> **Your role**: QA Engineer ensuring Character Detail v2 meets quality standards  
> **Time**: 35 minutes (focused) or 55 minutes (with team collaboration)  
> **Transformation**: From post-implementation testing to real-time quality gates

---

## üìñ Your Story in This Module

This is the payoff moment. The team has spent all day building context‚Äîinstructions, prompts, custom instructions, skills, MCP connections. Now they're unleashing an agent to build Character Detail v2 autonomously.

Your fear: An autonomous agent writing code AND tests without human oversight. What if it generates tests that look complete but miss critical scenarios? What if the tests pass but don't actually validate business requirements?

Your opportunity: You've already built the `testing.instructions.md` (Module 4) and the `bug-reproduction-test-generator` skill (Module 5). The agent has YOUR testing patterns. Now you'll see if your preparation pays off.

---

## üéØ Your Exercises

### Exercise 7.1: QA Validation of Agent-Generated Tests ‚≠ê *You lead this one*

**Your role**: Validate that agent-generated tests meet quality standards  
**Time**: 25 minutes  
**[View Exercise 7.1 ‚Üí](../EXERCISES.md#exercise-71-character-detail-v2--the-golden-thread-payoff)**

**What you'll do:**
- Review tests generated by the autonomous agent
- Verify your testing instructions were applied
- Check edge case coverage
- Validate that tests actually test business requirements

**Your "before" pain:**

Without your testing context, the agent generates superficial tests:

```javascript
describe('CharacterDetail', () => {
  it('renders correctly', () => {
    render(<CharacterDetail id="1" />);
    expect(screen.getByText('Walter White')).toBeInTheDocument();
  });
});
```

- ‚ùå No error case testing
- ‚ùå No loading state testing
- ‚ùå No edge cases (missing photo, empty episodes)
- ‚ùå No API failure scenarios
- ‚ùå Uses 'it' inconsistently with other tests

You spend 45 minutes rewriting the tests.

**Your "after" win:**

With your `testing.instructions.md` active, the agent generates:

```javascript
describe('CharacterDetail v2', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  describe('when data loads successfully', () => {
    it('should display character name, bio, and photo', async () => {
      mockApi.getCharacterFull.mockResolvedValue(mockCharacterData);
      
      render(<CharacterDetail id="1" />);
      
      await waitFor(() => {
        expect(screen.getByText('Walter White')).toBeInTheDocument();
        expect(screen.getByRole('img', { name: /walter white/i })).toBeInTheDocument();
      });
    });

    it('should display related characters from the same show', async () => {
      mockApi.getCharacterFull.mockResolvedValue({
        ...mockCharacterData,
        relatedCharacters: [{ id: 2, name: 'Jesse Pinkman' }]
      });
      
      render(<CharacterDetail id="1" />);
      
      await waitFor(() => {
        expect(screen.getByText('Jesse Pinkman')).toBeInTheDocument();
      });
    });
  });

  describe('when character has no photo', () => {
    it('should display placeholder image', async () => {
      mockApi.getCharacterFull.mockResolvedValue({
        ...mockCharacterData,
        photo_url: null
      });
      
      render(<CharacterDetail id="1" />);
      
      await waitFor(() => {
        expect(screen.getByRole('img', { name: /placeholder/i })).toBeInTheDocument();
      });
    });
  });

  describe('when API fails', () => {
    it('should display error message for 404', async () => {
      mockApi.getCharacterFull.mockRejectedValue({ status: 404 });
      
      render(<CharacterDetail id="1" />);
      
      await waitFor(() => {
        expect(screen.getByText('Character not found')).toBeInTheDocument();
      });
    });

    it('should display retry button for 500 errors', async () => {
      mockApi.getCharacterFull.mockRejectedValue({ status: 500 });
      
      render(<CharacterDetail id="1" />);
      
      await waitFor(() => {
        expect(screen.getByRole('button', { name: /retry/i })).toBeInTheDocument();
      });
    });
  });

  describe('when character has no episodes', () => {
    it('should display "No episodes" message', async () => {
      mockApi.getCharacterFull.mockResolvedValue({
        ...mockCharacterData,
        episodes: []
      });
      
      render(<CharacterDetail id="1" />);
      
      await waitFor(() => {
        expect(screen.getByText('No episodes found')).toBeInTheDocument();
      });
    });
  });
});
```

**Metrics:**
- **Test review time**: From 45 min to 5 min
- **Edge cases covered by first generation**: From 20% to 90%
- **Tests needing complete rewrite**: From 70% to 5%
- **Time saved per feature**: 40+ minutes

**Your transformation moment:**
> *"The agent didn't just generate tests‚Äîit generated MY tests. My patterns, my edge cases, my assertions. I spent 8 years learning what to test. Today, I spent 10 minutes encoding it. Now it's automatic."*

---

### Exercise 7.2: Real-Time Quality Gates ü§ù *Team collaboration*

**Your role**: Review agent work as it happens  
**Partners**: Marcus (running agent), David (architecture review), Sarah (implementation review)  
**Time**: 10 minutes  
**[View full exercise ‚Üí](../EXERCISES.md#exercise-71-character-detail-v2--the-golden-thread-payoff)**

**What you contribute:**

As the agent generates Character Detail v2, you review in real-time:

1. **Watch the test file creation**
   - Are tests in the correct location?
   - Do they follow `describe/it` structure?
   - Are mocks at module level?

2. **Check edge case coverage**
   - Loading states?
   - Error states (404, 500, network failure)?
   - Empty data (no episodes, no quotes)?
   - Null fields (missing photo, null bio)?

3. **Verify business requirements**
   - Do tests match acceptance criteria?
   - Are user journeys covered?
   - Is accessibility considered?

**Your review checklist:**

```markdown
## Elena's Quality Gate Checklist

### Test Structure
- [ ] Uses describe/it pattern consistently
- [ ] Mocks external dependencies at module level
- [ ] Each test has clear Arrange/Act/Assert sections
- [ ] Test names describe expected behavior

### Edge Case Coverage
- [ ] Tests loading state
- [ ] Tests error states (404, 500, network)
- [ ] Tests empty arrays (no episodes, no quotes)
- [ ] Tests null/undefined fields (no photo, no bio)

### Business Validation
- [ ] Tests match acceptance criteria from planning
- [ ] User journeys are covered (happy path + errors)
- [ ] Accessibility requirements are tested

### Integration Points
- [ ] API mocks match actual endpoint signatures
- [ ] Component renders with all data scenarios
- [ ] State management is tested
```

**Why this matters for you:**

You're not reviewing after the feature ships‚Äîyou're reviewing AS it's built. Early feedback is cheap feedback.

---

## üîó Connections to Your Work

### Skills You're Building
- **Real-time quality assurance**: Review as agents work
- **Quality automation validation**: Verify your patterns were applied
- **AI-assisted testing**: Let AI handle coverage, you handle strategy
- **Continuous testing culture**: Tests aren't afterthoughts

### How This Helps Your Real Work

**Traditional QA workflow:**
```
Agent builds feature ‚Üí Feature ships ‚Üí QA reviews ‚Üí Finds gaps ‚Üí Rework
```

**Module 7 QA workflow:**
```
Agent builds (with your patterns) ‚Üí Real-time review ‚Üí Ship with confidence
```

The difference:
- **Earlier feedback**: Issues caught during generation
- **Better coverage**: Your patterns applied automatically
- **Faster validation**: Structure is right, focus on logic
- **Higher confidence**: Tests aren't just passing, they're meaningful

### Artifacts You Validate
- `CharacterDetail.test.jsx` ‚Äî Component tests
- `characters.test.js` ‚Äî API endpoint tests
- Integration test coverage

---

## üí≠ Your Transformation Arc

**Before this module (your fears):**
- üò∞ Agent generates tests without understanding what to test
- üò∞ Tests look complete but miss critical scenarios
- üò∞ Autonomous AI removes human judgment from QA
- üò∞ My 8 years of expertise bypassed by automation

**After this module (your achievements):**
- ‚úÖ Agent generates tests USING my expertise (from testing.instructions.md)
- ‚úÖ Edge cases covered because I encoded them
- ‚úÖ My judgment shapes agent output, not replaced by it
- ‚úÖ Quality scales because my patterns scale

**Key insight:**
> *"The agent isn't replacing my testing expertise‚Äîit's applying it at scale. I spent years learning what to test. Now the agent knows it too. That's not automation replacing judgment‚Äîthat's judgment becoming policy."*

---

## üöÄ Quick Start Guide

**If you're short on time (25 minutes):**
1. Jump to Exercise 7.1
2. Review agent-generated tests for Character Detail v2
3. Verify your patterns were applied
4. Provide targeted feedback on gaps

**If you have full time (35 minutes):**
1. Exercise 7.1: QA validation (25 min)
2. Exercise 7.2: Real-time quality gates (10 min)
3. Update testing.instructions.md based on gaps found

**Want to go deeper?**
- Create a "post-agent-run" test review checklist
- Add accessibility testing requirements to instructions
- Build performance testing patterns

---

## üìä Your Success Metrics

| Metric | Without Testing Instructions | With Testing Instructions |
|--------|---------------------------|--------------------------|
| **Test review time** | 45 min | 5 min |
| **Edge cases in first generation** | 20% | 90% |
| **Tests needing rewrite** | 70% | 5% |
| **Time saved per feature** | ‚Äî | 40+ min |

---

## ‚û°Ô∏è Continue Your Journey

### Within This Module
- [View all exercises](../EXERCISES.md) for full team story
- [Marcus's path](marcus.md) to see agent implementation
- [David's path](david.md) to see architecture validation
- [Sarah's path](sarah.md) to see code review

### Next Module
Your next appearance: **[Module 9: Copilot CLI](../../09-copilot-cli/personas/elena.md)**

**What's next for you**: You'll use the CLI to run tests conversationally‚Äîdebugging failures, generating missing tests, and automating pre-push validation. The tests the agent created in Module 7 become the foundation for your CLI workflows in Module 9.

---

## üìö Resources for QA Engineers

**Official Documentation:**
- [VS Code: Agent Mode](https://code.visualstudio.com/docs/copilot/copilot-chat#_agent-mode)
- [GitHub Docs: Copilot Chat](https://docs.github.com/en/copilot/using-github-copilot/using-github-copilot-chat-in-your-ide)

**Testing-Specific Resources:**
- [React Testing Library Best Practices](https://testing-library.com/docs/guiding-principles/)
- [Jest Documentation](https://jestjs.io/docs/getting-started)
- [Testing Library Queries](https://testing-library.com/docs/queries/about)
